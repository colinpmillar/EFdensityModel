\documentclass{article}

\RequirePackage{geometry}
\geometry{verbose,tmargin=35mm,bmargin=30mm,lmargin=35mm,rmargin=35mm}


% ******************************* Line Spacing *********************************

%\renewcommand\baselinestretch{1.2}

% Choose linespacing as appropriate. Default is one-half line spacing as per the
% University guidelines

% \doublespacing
% \onehalfspacing
% \singlespacing
\setlength{\parindent}{0pt}
\setlength{\parskip}{12pt}


% ************************* Algorithms and Pseudocode **************************


\usepackage{algorithmicx}
\usepackage{algpseudocode}

% ***************************** Math and SI Units ******************************

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{siunitx} % use this package module for SI units
\usepackage{bm}           % load after all math to give access to bold math

% Distributions
\DeclareMathOperator{\GammaD}{Gamma}
\DeclareMathOperator{\NormD}{N}
\DeclareMathOperator{\BetaD}{Beta}
\DeclareMathOperator{\tD}{t}
\DeclareMathOperator{\BinomD}{Bin}
\DeclareMathOperator{\PoissonD}{Pois}
\DeclareMathOperator{\NegbinD}{NegBin}

% Functions
\DeclareMathOperator{\Beta}{B}

% Operators
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\CV}{CV}

% likelihood functions
\newcommand{\prob}[1]{\mathrm{Pr}\left( #1 \right)}
\newcommand{\Lik}[1]{\mathrm{L}\left( #1 \right)}
\newcommand{\logLik}[1]{l\left( #1 \right)}




% ******************************* Meta data ************************************

\title{Statistical aspects of Electrofishing}
\author{Colin Millar}
\date{\Sexpr{Sys.Date()}}

\begin{document}

<<settings, echo=FALSE, message=FALSE>>=
library(ef, quietly = TRUE)
@

\maketitle

\tableofcontents

Note that this is being drafted in paper style for my own purposes.  We can probably just thin this down a bit and turn this into a methods section and perhaps put other bits, if nessissary, into a short appendix.  It is also still developing so dont consider this as a draft as yet.  The methods are still under development.


% ------------------------------------------------------------------------------
%
%
%
% ------------------------------------------------------------------------------

\section{Introduction}

Large multispecies age-structured electrofishing datasets are statistically complex to model because of heirarchical structure in the data. Two processes define an electrofishing sample: capture probability $p$ and fish abundance $N$.  Millar et al. (2015) presented a model where capture probability was shown to vary with covariates describing habitat and sampling procedure.  After controling for these factors Millar et al. found that there remained considerable variation in the observations at the sample level. This between sample variation could be due to a number of variables not included in the model such as water temperature at time of sampling, electrical current used, light attenuation / cloud cover etc.  This additional variability was accounted for by using an approximate quasi-likelihood approach.

  In this document the same variables used in Millar et al. are used to model fish abundance and as with capture probability it is likely that fish abundance will show additional variability due to factors not included in the model, such as the proximity of redds or fine-scale habitat features. Additionally, it is also possible that the presence of one lifestage or species could inhibit or encourage the presence of another. Because of this, the abundances of each fish-type may show correlation between samples.

  This document develops a modelling approach to allow efficient model selection while accounting for between sample variation accross fish-type using generalised additive models.  The sampling efficiency of each sample is derived from a capture probability model arrived at using the procedure set out in Millar et al. (2015). This provides an offset with which to model density from the total catch. In order to correctly assess the significance of terms in the density model, it is, therefore,  nessisary to account for the uncertainty due to the estimation of capture probability. This is achieved using a simulation procedure.

  This document procedes as follows. First a model for single sample is described and then the case where a number of samples are made over sites with the same characteristics is considered.  This allows the development of an approach for dealing with correlation between lifestages.  This model is then extended to allow for habitat and temporal variation.



% ------------------------------------------------------------------------------
%
%
%
% ------------------------------------------------------------------------------

\section{A density model for a single sample}

The density $\lambda_k$ of fish-type $k$ ($k =$ trout-fry, trout-parr, salmon-fry, salmon-parr) at a single electrofishing site is determined solely by fish type.  Density is often modelled on the log scale so that
\begin{align}
  \log \lambda_k = \nu_k
\end{align}
If it is assumed that the abundance $N_k$ of each fish-type in the fished area at the time of sampling is a realisation of a Poisson process with rate $\lambda_k$, then the total count $T_k$ of each fish type is Poisson distributed with rate $q_kA\lambda_k$, where $q_k$ is the average probability of a fish of type $k$ apearing in the sample (Huggins, 1996).  The parameters $\nu_k$ can then be estimated by maximising the log-likelihood
\begin{align}
  L = \sum_k T_k\nu_k - e^{\nu_k}
\end{align}

Estimating $\nu_k$ is straightforward if $q_k$ is assumed known without error by using standard software for generalised linear models (GLMs).  For convience let
\begin{align}
  \bm{\nu} =
    \begin{pmatrix}
      \nu_{\text{trout-fry}} \\ \nu_{\text{trout-parr}} \\
      \nu_{\text{salmon-fry}} \\ \nu_{\text{salmon-parr}}
    \end{pmatrix}
\intertext{and}
  \bm{q} =
    \begin{pmatrix}
      q_{\text{trout-fry}} \\ q_{\text{trout-parr}} \\
      q_{\text{salmon-fry}} \\ q_{\text{salmon-parr}}
    \end{pmatrix}
\end{align}

then, if there is sufficient numers of fish caught, the maximul likelihood estimate $\hat{\bm{\nu}}|\hat{\bm{q}}$ (i.e. conditional on the ML estimate of the $q_k$) is multivariate normally distributed with mean $\bm{\nu}|\hat{\bm{q}}$ and with a diagonal covariance matrix. Diagonal beacause conditional on $q_k$, the total counts are realisations of independent poisson distributions.

However, because $\hat{\bm{q}}$ is itself an estimate, it also has a distribution and the covariance matrix of which may not be diagonal.  Hence, after incorporating the error from the capture probability model into the density model, the unconditional estimate $\hat{\bm{\nu}}$ is approximately
\begin{align}
  \hat{\bm{\nu}} \sim \NormD(\bm{\nu}, \bm{R})
\end{align}
where $R$ is approximately
\begin{align}
  I(\hat{\bm{\nu}})^{-1} + \frac{d\hat{\bm{q}}}{d \beta}' I(\hat{\beta})^{-1} \frac{d\hat{\bm{q}}}{d \beta}
\end{align}
from Huggins + GLM poisson error. The estimation of the variance matrix $R$ is given in Appendix A.  The covariance matrix $R$ can be used to construct confidence intervals etc.





% ------------------------------------------------------------------------------
%
%
%
% ------------------------------------------------------------------------------

\section{Between sample variation}

Following Fryer (1991) between sample variation can be incorporated using a two stage procedure where
\begin{align}
  \bm{\nu}_i \sim \NormD(\bm{\alpha}, \bm{R}_i + \bm{D})
\end{align}

The point here is to get a good estimate of the variance matrix $D$ describing the covariance between species and lifestages.

Given the matrix $D$ the parameters $\bm{\alpha}$ can be estimated by maximising the penalised log-likelihood
\begin{align}
  L = \sum_{ik} T_{ik} \nu_{ik} - e^{\nu_{ik}} -  \sum_i \bm{\nu}_i' \bm{D\nu}_i
\end{align}
this model can be fitted in mgcv by specifying a offset penalty matrix.





% ------------------------------------------------------------------------------
%
%
%
% ------------------------------------------------------------------------------

\section{Quick go at estimating D}


<<quick_try>>=

# simulate a correlated process
Di <- matrix(c(1, -.8, -.8, 1), 2, 2)
nsamples <- 100
lambda <- MASS::mvrnorm(n = nsamples, mu = c(1,4), Sigma = Di)
obs_lambda <- lambda + rnorm(nsamples*2, 0, sqrt(2))

dat <- data.frame(stage = factor(rep(c("fry", "parr"), each = nsamples)),
                  id = factor(1:(2*nsamples)),
                  sample = factor(rep(1:nsamples, 2)),
                  density = c(obs_lambda))

# set up smoother for fitting
# this is the inverse of the joint covariance matrix
D <- solve(Di %x% diag(nsamples))

# design matrices
Xm <- model.matrix(~ stage - 1, data = dat)
Xi <- model.matrix(~ id - 1, data = dat)

# now lets fit in mgcv
library(mgcv)
# first double the length of dat and then weight to zero
#  to fool gam into thinking there is enough data
dat2 <- rbind(dat, dat)
dat2 $ weights <- rep(1:0, each = nrow(dat))
dat2 $ Xm <- rbind(Xm, Xm)
dat2 $ Xi <- rbind(Xi, Xi)

# fit
g1 <- gam(density ~ Xm + Xi - 1, paraPen=list(Xi=list(0.5*D, sp = 1)),
          data = dat2, weights = weights)
# scale should be 0.2
g1 $ sig2
# no. of parameters estimated = 202
# (no. of samples * 2 stages + 2 stage means)
# but number of model degrees of freedom:
sum(g1$edf)
# fitted sample effects
dat $ fitted <- Xm %*% coef(g1)[grep("Xm", names(coef(g1)))] +
                Xi %*% coef(g1)[grep("Xi", names(coef(g1)))]
#
fitted <- matrix(dat$fitted, ncol = 2, dimnames = list(NULL, c("fry", "parr")))
par(mfrow = c(2,2))
plot(obs_lambda)
plot(fitted)
plot(lambda, col = "red", cex = 0.5)
points(fitted, cex = 0.5)
plot(lambda, type = "n")
arrows(fitted[,1], fitted[,2], lambda[,1], lambda[,2], length = 0.05, code = 1)
cor(fitted)
cov(fitted)
cov(lambda)

# have a look at confidence intervals around stage effect
cbind(est = coef(g1)[1:2],
      sd = sqrt(diag(vcov(g1)[1:2,1:2])))
cov2cor(vcov(g1)[1:2,1:2])

# what if we didnt model the correlation...
g2 <- lm(density ~ stage - 1, data = dat)
cbind(est = coef(g2),
      sd = sqrt(diag(vcov(g2))))
cov2cor(vcov(g2))
@




% ------------------------------------------------------------------------------
%
%
%
% ------------------------------------------------------------------------------

\section{An analysis of simulated data}

<<simulation_settings, echo=FALSE>>=
n <- 30
rs <- 0.5; rl <- -0.8
sig <- 0.1
alpha <- rep(log(40), 4)
#
Rl <- diag(2); Rl[2:3] <- rl
Rs <- diag(2); Rs[2:3] <- rs
R <- Rs %x% Rl
D <- sig*R
@

Simulation scheme is as follows. \Sexpr{n} electrofishing samples are simulated, in order to make things interesting it is assmumed that salmon and trout are often found together while parr inhibit fry, so that
\begin{align}
  \bm{D} = \sigma^2 \bm{R} = \sigma^2 \big( \bm{R}_\text{species} \otimes \bm{R}_\text{life-stage} \big)
\end{align}
where the $\bm{R}$ matrixes are 2x2 correlation matrices with a correlation of \Sexpr{rs} between species and \Sexpr{rl} between lifestages resulting in
\begin{align}
  \bm{R} =
    \begin{bmatrix}
      1.0 & -0.8 &  0.5 & -0.4 \\
     -0.8 &  1.0 & -0.4 &  0.5 \\
      0.5 & -0.4 &  1.0 & -0.8 \\
     -0.4 &  0.5 & -0.8 &  1.0
    \end{bmatrix}
\end{align}
Simulated densities for each fish type are shown below, each has a mean of 40 fish per metre square and a CV of around 10\%
<<simulation_nu, echo=FALSE>>=
set.seed(235987)
numat <- MASS::mvrnorm(n, alpha, D)
colnames(numat) <- c("Trout-fry", "Trout-parr", "Salmon-fry", "Salmon-parr")
ndata <- expand.grid(lifestage = c("fry", "parr"),
                     species = c("Trout", "Salmon"),
                     sample = 1:n)
ndata $ nu <- exp(c(numat))
@

<<simulation_nu_plot, echo=FALSE>>=
plot(as.data.frame(exp(numat)))
@

<<simulation_p, echo=FALSE>>=
pdata <- expand.grid(pass = 1:3,
                     lifestage = c("fry", "parr"),
                     species = c("Trout", "Salmon"),
                     sample = 1:n)
pdata$id <- with(pdata, as.numeric(factor(paste(sample, lifestage, species))))
pmodel <- ~ lifestage + species
Xp <- model.matrix(pmodel, pdata)
betap <- c(0.5, 0.5, -0.2)
pdata $ p <- 1/(1+exp(-Xp %*% betap))
pmat <- matrix(pdata $ p, 3)
pimat <- rbind(pmat[1,], (1-pmat[1,])*pmat[2,], (1-pmat[1,])*(1-pmat[1,])*pmat[3,])
pdata $ pi <- c(pimat)
pdata $ row <- 1:nrow(pdata)
pdata <- merge(pdata, ndata)
pdata <- pdata[order(pdata$row),]
@

<<simulation_y, echo=FALSE>>=
# y is poisson(pi * A * nu)
set.seed(345455)
pdata $ y <- rpois(nrow(pdata), pdata$pi * pdata$nu)
ndata $ y <- colSums(matrix(pdata $ y, 3))
@

having simulated some data we can fit a capture probability model

<<fitting_p, message=FALSE, eval = FALSE>>=
pmod <- efp(y ~ lifestage + species, pass = pass, id = id,
            data = pdata)
@

And now we can fit a density model to each sample


<<fitting_nu, eval = FALSE>>=
pmat <- matrix(fitted(pmod, type = "p"), 3)
ndata $ pi <- 1 - (1-pmat[1,])*(1-pmat[1,])*(1-pmat[3,])
nmod <- glm(y ~ lifestage:species:factor(sample)-1, family = poisson,
            data = ndata, offset = log(ndata$pi))
@

Now we can calculate $R_i$ for each $\nu_i$. $R_i$ is the total error in estimating $\nu_i$, one way to get this is via bootstrapping

<<boot_nu, cache=TRUE, message=FALSE, eval = FALSE>>=
do.one.boot <- function(...) {
  bsamp <- sample(unique(ndata$sample),
                  length(unique(ndata$sample)),
                  replace = TRUE)
  bpdata <- pdata[pdata$sample %in% bsamp,]
  bndata <- ndata[ndata$sample %in% bsamp,]

  pmod <- efp(y ~ lifestage + species, pass = pass, id = id,
              data = bpdata)
  pmat <- matrix(fitted(pmod), 3)
  bndata $ pi <- 1 - (1-pmat[1,])*(1-pmat[1,])*(1-pmat[3,])
  nmod <- glm(y ~ lifestage:species:factor(sample)-1, family = poisson,
              data = bndata, offset = log(bndata$pi))
  out <- matrix(coef(nmod), nrow = 4)
  colnames(out) <- paste(sort(unique(bsamp)))
  # add in poisson estimation error
  out[] <- MASS::mvrnorm(1, coef(nmod), vcov(nmod))
  out
}
nboot <- 1000
sim <- replicate(nboot, do.one.boot(), simplify = FALSE)
sim <- sapply(sim,
              function(x) {
                out <- matrix(NA, 4, n)
                colnames(out) <- 1:n
                out[,colnames(x)] <- x
                out
              })
dim(sim) <- c(4, n, nboot)
Ri <- lapply(1:n,
            function(i) {
              x <- t(sim[,i,])
              var(x, na.rm = TRUE)
            })
Ri[[1]]
unname(vcov(nmod)[1:4,1:4])
@


another way to get this is via MCMC sampling

<<mcmc_nu, cache=TRUE, message=FALSE, eval = FALSE>>=
samp <- simulate(pmod, nsim = 1000)
library(rstan)
sim <- extract(samp)$piT

dim(sim) <- c(4, n, 1000)
Ri <- lapply(1:n,
            function(i) {
              x <- t(sim[,i,])
              var(x, na.rm = TRUE)
            })
Ri[[1]]
unname(vcov(nmod)[1:4,1:4])
@


And then estimate $D$!


Then finally re-estmimate nu and get appropriate confidence intervals!

% ------------------------------------------------------------------------------
%
%
%
% ------------------------------------------------------------------------------

\section{Modelling abundance accross Scotland}

Here we extend the model to incorporate covariates.  So the task here is to fit suitable complex models to each species-lifestage, then fit a sample-wise model with the predictions from the complex models as offsets. THen estimate $D$ from these.




\end{document}
